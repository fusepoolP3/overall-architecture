# Integration of SILK component into platform

Deliverable 3.2

Delivery date: 15

## Document History

|Ver.          | Name         | Date         | Remark       |
|--------------|--------------|--------------|--------------|
|v0.1          | Luigi Selmi  | 2014-11-28   | First draft |


## Executive Summary

The 4th and last "expectation of behaviour" specified by Tim Berners-Lee in his proposal to create a web of data was
to "include links to other URIs so that they can discover more things". A particular class of these links are those that
connect different representations of the same thing. Being able to connect records coming from different data sources is
a fundamental objective of any data integration effort starting from putting together records of in different spreadsheets to integrating data assets owned by one or more companies and finally merging different views of a subject in the World Wide Web where the AAA slogan must apply: "Anyone can say Anything about Any topic".

The objective of the task has been to provide a support for disambiguating and interlinking entities that are added to a LDP container.

## Acronyms and Abbreviations



| Acronym |                 Description                  |
|---------|----------------------------------------------|
| API     | Application Programming Interface            |
| BUAS    | Bern University of Applied Sciences          |
| FP3     | Fusepool P3                                  |
| HTTP    | Hypertext Transfer Protocol                  |
| HTTPS   | Secure Hypertext Transfer Protocol           |
| IRI     | Internationalized Resource Identifier        |
| LDP     | Linked Data Platform                         |
| RDF     | Resource Description Framework               |
| RDFS    | RDF Schema                                   |
| REST    | Representational State Transfer              |
| URI     | Uniform Resource Identifier                  |
| URL     | Uniform Resource Locator                     |




## Normative namespaces

In this document the prefixes used in [CURIEs](http://www.w3.org/TR/curie/) shall refer the following
IRI prefixed:


| Prefix |                                                                                                                                                                                             Namespace                                                                                                                                                                                              |
|--------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| rdf    | [http://www.w3.org/1999/02/22-rdf-syntax-ns\#](http://www.w3.org/1999/02/22-rdf-syntax-ns)
| rdfs   | [http://www.w3.org/2000/01/rdf-schema\#](http://www.w3.org/2000/01/rdf-schema) |
| xsd    | [http://www.w3.org/2001/XMLSchema\#](http://www.w3.org/2001/XMLSchema)     |
| dct    | [http://purl.org/dc/terms/](http://purl.org/dc/terms/) |
| ldp    | [http://www.w3.org/ns/ldp\#](http://www.w3.org/ns/ldp#)|
| fp3    | [http://vocab.fusepool.info/fp3\#](http://vocab.fusepool.info/fp3#)|
| eldp   | [http://vocab.fusepool.info/eldp\#](http://vocab.fusepool.info/eldp#)   |
| trans  | [http://vocab.fusepool.info/transformer\#](http://vocab.fusepool.info/transformer#) |
| fam    | [http://vocab.fusepool.info/fam\#](http://vocab.fusepool.info/fam#) |

## Background
(Why was this task created, what is the goal of the subtask and how does it contribute to the deliverable )

This task has been proposed to offer a mechanism to a user of the platform to discover entities that have been given different names by different authors that refer to the same thing in order to merge their descriptions and augment the knowledge about the entity. This is a crucial task for any user of the platform since what she likely wants is not a collection of disconnected graphs but a well connected knowledge base. The task of disambiguating entities has been given different name by different communities: record linkage, deduplication, entity resolution and so forth. All the methodologies that have been developed to discover equivalent entities are based on the assumption of the identity of indiscernibles [2] that is attributed to the German philosopher Gottfried Wilhelm Leibniz, that states that there cannot be separate objects that have all their properties exactly the same. In order to ascertain whether two entities are the same two types of inferences can be evaluated. On one hand an identity can be inferred from functional and inverse functional properties when there are some statements that relates two entities and the properties are of the type mentioned. As an example, if the following facts are stated

:Bob :hasFather :John  
:Bob :hasFather :Johnny  

and we know that  

:hasFather rdf:type owl:FunctionalProperty  

the identity :John owl:sameAs :Johnny can be inferred by a reasoner. The problem is that it doesn't happen very often that an entity in a data set is related to an entity in a different data set through a functional property. Inverse functional properties like passport number, driver license fiscal codes, are used more frequently. As an example, if the following facts are stated

:John :hasPassport "A123456"  
:Johnny :hasPassport "A123456"

and we know that

:hasPassport rdf:type owl:InverseFunctionalProperty

then a reasoner can infer :John owl:sameAs :Johnny. That said, such properties are not always available and it can happen that the values contain errors so that it is always better to decide about the identity of two entities on more than one single property. In order to disambiguate two entities by their description, i.e. comparing their properties, we must analyze the following aspects

* the vocabulary used for the description  
* the set of properties that are considered to be enough to distinguish two entities globally  
* missing values, spelling errors and lexical differences in the properties literal values

Starting with the case in which all the entities are described using the same vocabulary, so that there is no ambiguity in the meaning of the properties, we have to decide which properties must be compared in order to distinguish two entities globally in the Semantic Web and Linked Data world. In the relational database world this decision is similar to the definition of a primary key for a tuple. The type of the entities is one of such property that is usually available or can be easily inferred. For entities like persons properties like name, place and date of birth are considered to be enough in most cases. For entities like organizations the same is for the name, the registered office or its address. In case some of these properties are missing we will have to consider the uncertainty in the value that is calculated as a result of the comparisons of all the properties used. Coming to the third point of the comparison issues, many algorithms have been proposed to determine the similarity between two strings. A similarity measure tells us in a numeric format which is the distance between two strings. Good overviews of such algorithms are given in [5] and [6]. In case the vocabulary used for the properties is different a mapping must be defined between the different terms used for the properties. The result of a comparison of two entities of the same type with semantically equivalent properties can be defined as the sum of all the similarity values between the properties used in the comparison of two entities. One property can be more relevant in the comparison of two entities so that it can be weighted. The result must be used to decide automatically if the two entities are a match or a non match or if a manual intervention is needed to disambiguate the two entities. A matching or linkage rule can defined setting upper and lower threshold values so that a comparison result above the upper value will trigger a match, a result below the lower thershold will trigger a non- match and finally a value between the lower and upper thresholds will wait for a human intervention to be solved. The first theoretical framework in the field of record linkage was proposed by Fellegi and Sunter in [7].  

* The owl:sameAs relation: simmetry, reflexivity, transitivity  


Meaning of the property owl:sameAs:  
if two entities A and B are believed to be the same then, for substitution axiom, every sentence that is true of A must be true of B. Translated in RDF this principle entails that for each triple in which A is subject or object a new triple can be inferred by a reasoner with B in place of A and viceversa. The issue with the given semantics of the owl:sameAs property is that there might be good reasons (see [4]) to not believe all the claims about the individual A made by an external data provider and at the same time we are not assured our claims are shared by the external data provider if those claims were not already in the data set. The decision in the first case could depend on the provenance of the data set.  

Alignment of the properties used to describe the entities.  

Linkage rules, similarity measures (distance metrics), thresholds  

UC 1) A user wants to discover duplicates in a RDF data set  
UC 2) A user wants to interlink entities, like persons, organizations or places, in a container to entities in a public data  set

## Execution/Implementation
(Describe the strategy to implement the task, describe how the risk known upfront were taken into account, describe the actual implementation, describe all trial and error, discussions, failures etc.)

* Implement  proprietary solution  
* Choose a tool that provides common algorithms and metrics, configurable and allows extensions  
* Any solution must fit in the platform architecture  
* Two tools have been tested LIMES and SILK: description of the tools, configurability, performances, license  
* issue with blocking  
* SILK selected as it comes with Apache 2.0 license.  
* Issues with geographical data: differnt formats, ShapeFile, CSV, JSON, XML
* Issues with geographical data: coordinates in different reference system (WGS84, UTM)
* Issues with geographical data: Incosistent use of vocabularies
* Issues with geographical data: geocoding of addresses


## Solution
(Describe the solution in detail, start with the benefit the solution provides, then go to the technical details.)

* Implementation of the transformer (based on the REST architecture)
* Description of the tool (SILK)
* Description of the transformer

## Future work
(Briefly outline how this solution or the way to implement it could be improved by others.)

* Use of other types of topological relationships by developing an extension for Jena or Virtuoso
* Use of OpenStreetMap or LinkedGeoData for interlinking  


## References
[1] [Tim Berners-Lee - Linked Data](http://www.w3.org/DesignIssues/LinkedData.html)  
[2] [Identity of indiscernibles](http://plato.stanford.edu/entries/identity-indiscernible/)  
[3] [D. Allemang, J. Hendler - Semantic Web for the Working Ontologist]  
[4] [H. Alpin, I. Herman, P. Hayes - When owl:sameAs isn't the Same: An Analysis of Identity Links on the Semantic Web ]  
[5] [A. Elmagarmid et al. - Duplicate Record Detection: A Survey]  
[6] [W. Winkler - Matching and Record Linkage]  
[7] [I. Fellegi, A. Sunter - A Theory For Record Linkage]  
